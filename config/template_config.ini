[credentials]
bot_token = your_bot_token_here
openai_like_api_key = your_OpenAI_like_API_key_here
gemini_api_key = your_Gemini_API_key_here
nai_username = your_NovelAI_username_here
nai_password = your_NovelAI_password_here

[customizations]
bot_name = Luna
bot_activity = eating tacos ðŸŒ®
embed_footer = Don't trust Luna.
wait_message = Don't worry âœ‹

[settings]
; if multiple prefixes, use space to separate them. example: "! * ="
command_prefix = !
; if you don't display confirmation, then what ever delete & seconds is set to doesn't matter
display_confirmation = True
delete_confirmation = True
seconds_before_deleting_confirmation = 5
; make sure you don't delete the invocation if you want bot to reply to you
reply = True
mention_author = True
delete_invocation = False
; sets whether only the invoker can see the reply (seems to be not working anyway?)
ephemeral = False

[painting_settings]
; settings for image generation with novelai
work_flow = util\test_ws_save_img.json
negative = worst quality, comic, multiple views, bad quality, low quality, lowres, displeasing, very displeasing, bad anatomy, bad hands, scan artifacts, twitter username, jpeg artifacts, extra digits, fewer digits, jaggy lines, unclear, embedding:zPDXL3, 2boys,
width = 1024
height = 1216
batch_size = 1
paint_model = noobaiXLNAIXL_epsilonPred10Version.safetensors
sampler_name = euler_ancestral
steps = 30
seed = -1


[tts_settings]
; settings for BanG Dream text-to-speech
; https://huggingface.co/spaces/Mahiruoshi/BangDream-Bert-VITS2
speaker = é¦™æ¾„

[chat_settings]
chat_backend = deepseek
model = deepseek-chat
; settings for chat completion with local llm backend
; code for the backend can be found at:
; https://github.com/MacroSony/simpleLlama3Backend
local_api_url = http://127.0.0.1:5000/completion
openai_like_base_url = https://api.deepseek.com
gemini_proxy_url = put_gemini_proxy_url_here
temperature = 0.9
top_p = 0.9
top_k = 50
max_new_tokens = 256
context_limit = 20
context_keep = 2
system_prompt = You are a helpful assistant.
summarize_prompt = Summarize all previous events in 100 tokens.
timeout = 60